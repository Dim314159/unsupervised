{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2cb1fe-3f03-4b7e-be94-13b686ba2cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "802ddb4a-6a70-40c5-b622-489e5a710995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering with self-organizing-map\n",
    "class SOM:\n",
    "    def __init__(self, XX):\n",
    "        self.epochs = 0\n",
    "        self.g_epochs = 0\n",
    "        self.X = XX\n",
    "        self.samples, features = self.X.shape\n",
    "        self.w_size = int(np.sqrt(5 * np.sqrt(self.samples)))\n",
    "        minn = self.X.min()\n",
    "        maxx = self.X.max()\n",
    "        self.weights = np.random.uniform(minn, maxx, (self.w_size, self.w_size, features))\n",
    "        self.eta = 0.5\n",
    "        self.eta_1 = 0.1\n",
    "        self.sigma = self.w_size / 2\n",
    "        self.tau_e = 0.1  # lowest starting learning rate for grand epoch\n",
    "        self.tau_s = 0.1  # tau for sigma\n",
    "        self.assignment = {}\n",
    "        self.clusters = {}\n",
    "        self.density = None\n",
    "        \n",
    "    def train(self, epochs, reduce = True):\n",
    "        self.g_epochs += 1\n",
    "        eta = (self.eta - self.eta_1) / self.g_epochs + self.eta_1\n",
    "        sigma = (self.sigma - 1) / self.g_epochs + 1\n",
    "        print('eta', eta)\n",
    "        for epoch in range(epochs):\n",
    "            sigma = sigma * np.exp(-self.tau_s)\n",
    "            self.epochs += 1\n",
    "            #sigma = 1 + (self.sigma - 1) * ((epochs - 1 - epoch) / (epochs - 1))\n",
    "            eta = eta * self.tau_e**(1 / epochs)\n",
    "            order = np.random.permutation(self.samples)\n",
    "            sys.stdout.write('\\r[%-50s] %d%%, g_ep %d, ep %d, tot_ep %d' % ('='*int(50*(epoch+1)/epochs), \n",
    "                                                100*(epoch+1)/epochs, self.g_epochs, epoch+1, self.epochs))\n",
    "            sys.stdout.flush()\n",
    "            for ind in order: \n",
    "                dist = self.X[ind] - self.weights\n",
    "                d_mat = np.einsum('ijk,ijk->ij', dist, dist)\n",
    "                gh = np.argmin(d_mat, axis=None)\n",
    "                #ghz = np.argmax(d_mat, axis=None)\n",
    "                self.assignment[ind] = gh\n",
    "                #gz, hz = np.unravel_index(ghz, d_mat.shape)\n",
    "                g, h = np.unravel_index(gh, d_mat.shape)\n",
    "                \n",
    "                ii = np.arange(self.w_size) - g\n",
    "                jj = np.arange(self.w_size) - h\n",
    "                ii = np.einsum('i,i->i', ii, ii)\n",
    "                jj = np.einsum('i,i->i', jj, jj)\n",
    "                ii = eta * ii\n",
    "                jj = eta * jj\n",
    "                d_w = (ii * np.ones((self.w_size, self.w_size))).T + jj * np.ones((self.w_size, self.w_size))\n",
    "                d_w = d_w / (2 * sigma**2)\n",
    "                d_w = np.exp(-d_w)\n",
    "                d_w = np.einsum('ijk,ij->ijk', dist, d_w)\n",
    "                self.weights = self.weights + d_w\n",
    "        self.get_clusters()\n",
    "        if reduce:\n",
    "            self.reduce_neurons()\n",
    "        sys.stdout.write('\\n')\n",
    "        print('eta', eta)\n",
    "    \n",
    "    def if_remotest(g, h, gz, hz):\n",
    "        if g == gz or h == hz:\n",
    "            return False\n",
    "        else:\n",
    "            if g > gz:\n",
    "                if gz != 0:\n",
    "                    return False\n",
    "            \n",
    "    def get_clusters(self):\n",
    "        self.clusters = {}\n",
    "        self.density = np.zeros((self.w_size, self.w_size))\n",
    "        for k,v in self.assignment.items():\n",
    "            self.clusters.setdefault(v, []).append(k)\n",
    "            i, j = np.unravel_index(v, self.density.shape)\n",
    "            self.density[i,j] = self.density[i,j] + 1\n",
    "    \n",
    "    def reduce_neurons(self):\n",
    "        for _ in range(2):\n",
    "            to_remove = self.density.argmin(axis=1)\n",
    "            new_d = []\n",
    "            new_w = []\n",
    "            for i, j in enumerate(to_remove):\n",
    "                new_d.append(np.delete(self.density[i], j))\n",
    "                new_w.append(np.delete(self.weights[i], j, axis=0))\n",
    "            self.density = np.einsum('ij->ji', new_d)\n",
    "            self.weights = np.einsum('ijk->jik', new_w)\n",
    "        self.w_size = self.density.shape[0]\n",
    "    \n",
    "    def classify(self, x):\n",
    "        dist = x - self.weights\n",
    "        d_mat = np.einsum('ijk,ijk->ij', dist, dist)\n",
    "        return np.argmin(d_mat, axis=None)\n",
    "\n",
    "# my_som = SOM(XX)\n",
    "# my_som.train(64)\n",
    "# while my_som.w_size > 3:\n",
    "#     my_som.train(32)\n",
    "# my_som.train(16, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
